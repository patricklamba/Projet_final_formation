# test_acces_fondamental.py
import requests
from bs4 import BeautifulSoup
import time

def test_acces_sites():
    """Test minimal d'accÃ¨s aux sites de fondamentaux"""
    
    sites = {
        "Investing.com Ã‰conomie": "https://fr.investing.com/economic-calendar/",
        "FXStreet ActualitÃ©s": "https://www.fxstreet.fr/actualites",
        "DailyFX Calendrier": "https://www.dailyfx.com/economic-calendar",
        "ForexFactory": "https://www.forexfactory.com/calendar",
        "Bloomberg Markets": "https://www.bloomberg.com/markets",
        "Reuters Business": "https://www.reuters.com/business/"
    }
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    
    print("ğŸ” TEST D'ACCÃˆS AUX SITES FONDAMENTAUX")
    print("=" * 60)
    
    for nom_site, url in sites.items():
        try:
            print(f"\nğŸŒ Test: {nom_site}")
            print(f"   ğŸ“¡ URL: {url}")
            
            # Test de connexion
            response = requests.get(url, headers=headers, timeout=10)
            
            print(f"   ğŸ“Š Statut: {response.status_code}")
            
            if response.status_code == 200:
                # Test du parsing
                soup = BeautifulSoup(response.content, 'html.parser')
                title = soup.find('title')
                print(f"   âœ… ACCÃˆS RÃ‰USSI - Titre: {title.get_text() if title else 'Non trouvÃ©'}")
                
                # Chercher des Ã©lÃ©ments de contenu
                articles = soup.find_all(['article', 'div'], class_=lambda x: x and any(word in str(x).lower() for word in ['news', 'article', 'event', 'calendar']))
                print(f"   ğŸ“° Ã‰lÃ©ments trouvÃ©s: {len(articles)}")
                
            elif response.status_code == 403:
                print("   âŒ ACCÃˆS BLOQUÃ‰ (403 Forbidden)")
            elif response.status_code == 404:
                print("   âŒ PAGE NON TROUVÃ‰E (404)")
            else:
                print(f"   âš ï¸  Statut anormal: {response.status_code}")
                
        except requests.exceptions.Timeout:
            print("   âŒ TIMEOUT - Site trop lent")
        except requests.exceptions.ConnectionError:
            print("   âŒ ERREUR CONNEXION")
        except Exception as e:
            print(f"   âŒ ERREUR: {e}")
        
        # Pause entre les tests
        time.sleep(2)

def test_calendrier_economique():
    """Test spÃ©cifique des calendriers Ã©conomiques"""
    print("\nğŸ“… TEST CALENDRIERS Ã‰CONOMIQUES")
    print("=" * 50)
    
    calendriers = {
        "Investing.com Calendar": "https://fr.investing.com/economic-calendar/",
        "ForexFactory Calendar": "https://www.forexfactory.com/calendar",
        "DailyFX Calendar": "https://www.dailyfx.com/economic-calendar"
    }
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    for nom, url in calendriers.items():
        try:
            print(f"\nğŸ“Š Test: {nom}")
            response = requests.get(url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # Chercher des Ã©vÃ©nements Ã©conomiques
                events = soup.find_all(['tr', 'div'], class_=lambda x: x and any(word in str(x).lower() for word in ['event', 'calendar', 'row']))
                
                print(f"   âœ… ConnectÃ© - Ã‰vÃ©nements potentiels: {len(events)}")
                
                # Afficher quelques Ã©vÃ©nements trouvÃ©s
                event_count = 0
                for event in events[:3]:  # Juste les 3 premiers
                    text = event.get_text(strip=True)
                    if text and len(text) > 20:
                        print(f"   ğŸ“ {text[:80]}...")
                        event_count += 1
                
                if event_count == 0:
                    print("   â„¹ï¸  Aucun Ã©vÃ©nement trouvÃ© (peut nÃ©cessiter sÃ©lecteurs spÃ©cifiques)")
                    
            else:
                print(f"   âŒ Erreur: {response.status_code}")
                
        except Exception as e:
            print(f"   âŒ Erreur: {e}")
        
        time.sleep(1)

if __name__ == "__main__":
    print("ğŸ¯ TEST MINIMAL D'ACCÃˆS - ANALYSE FONDAMENTALE")
    print("Objectif: VÃ©rifier quels sites sont accessibles pour le scraping")
    print("=" * 70)
    
    # Test gÃ©nÃ©ral des sites
    test_acces_sites()
    
    # Test spÃ©cifique calendriers
    test_calendrier_economique()
    
    print("\n" + "=" * 70)
    print("ğŸ“‹ RÃ‰SUMÃ‰ DES TESTS")
    print("âœ… Sites en vert: Bon pour le scraping")
    print("âŒ Sites en rouge: ProblÃ¨mes d'accÃ¨s")
    print("âš ï¸  Sites nÃ©cessitent peut-Ãªtre des sÃ©lecteurs spÃ©cifiques")